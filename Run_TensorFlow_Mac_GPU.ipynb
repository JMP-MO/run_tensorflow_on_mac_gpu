{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06bfb704-84cf-4afc-a010-bb3f2267b9eb",
   "metadata": {},
   "source": [
    "# How to run TensorFlow on Apple mac M-series ğŸŸ\n",
    "\n",
    "The TensorFlow machine learning framework is supposed to automatically detect and prioritise the use of GPUs over CPUs. <br>\n",
    "However, when using Tensorflow on a M-series (Apple Silicon) mac I have found that TensorFlow does not automatically detect and use your Apple GPU; increasing training time significantly. \n",
    "\n",
    "* I have listed the steps below to create an environment which will enable TensorFlow to recognise and use Apple's GPUs on M-series chips.\n",
    "* I have also included an example comparing Apple's GPU and CPU (using a M1-Pro laptop) in a small TensorFlow ML project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b900cfb-0260-4af3-beee-6cf757bf70c9",
   "metadata": {},
   "source": [
    "### ğŸ“¦ Environment requirements \n",
    "\n",
    "I used Conda to create a new envirnment with python included. Then manually installed the following pip packages. Then manually added other conda packages I needed. I experimented with creating a YAML file with these instructions, however have continued to find issues with package conflicts when automating this process, but this manual method worked.  \n",
    "\n",
    "**Step-bystep Environment Instructions:**\n",
    "\n",
    "1. Create a new environment with python.\n",
    "2. pip install tensorflow-macos\n",
    "3. pip install tensorflow-metal\n",
    "4. conda install your other packages such as jupyter, pandas etc...\n",
    "\n",
    "Tensorflow should now automatically use your Mac M-series GPU if it can locate them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fffda3a-b4dc-41bc-96ea-ca26d2ce0acf",
   "metadata": {},
   "source": [
    "### ğŸ’¿ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41dd7ff-d0a5-4316-be8d-f60cddbe0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1730c7-6b7a-4aa9-869f-378e9ac92101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs 1\n"
     ]
    }
   ],
   "source": [
    "# Check for GPUs!\n",
    "print(\"Num GPUs\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b41054-e1a7-4d3e-8ef5-aa1a4a6b3ffc",
   "metadata": {},
   "source": [
    "### ğŸ§ª Simple example model and data to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b376ea33-3c10-4f2f-a393-eecd3e1586de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow-m1-gpu/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n",
      "2025-02-07 13:24:06.632305: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2025-02-07 13:24:06.632332: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-02-07 13:24:06.632337: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-02-07 13:24:06.632352: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-02-07 13:24:06.632363: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Create a simple CNN model\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=(128, 128, 1)), \n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate random input data (for testing purposes)\n",
    "x_train = np.random.random((10000, 128, 128, 1))  # 10000 images, 128x128 pixels, grayscale\n",
    "y_train = np.random.randint(10, size=(10000,))   # Random labels for 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c4238-6599-4a5d-9e3c-39d8874a75e1",
   "metadata": {},
   "source": [
    "### ğŸƒâ€â™‚ï¸â€â¡ï¸ Using Mac M-series GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b7b5cc-975e-4623-b690-816561199508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 13:24:11.074972: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 30ms/step - accuracy: 0.1019 - loss: 2.3136\n",
      "Epoch 2/2\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.1031 - loss: 2.3022\n",
      "CPU times: user 11.7 s, sys: 7.18 s, total: 18.9 s\n",
      "Wall time: 27.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x164f9bd10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train the model for a few epochs (to test GPU usage)\n",
    "model.fit(x_train, y_train, epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fef381-c7b4-4f88-854a-a49ea1043f83",
   "metadata": {},
   "source": [
    "### ğŸŒ Using Mac M-series CPU only - for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d17c44-cbc7-43a0-8d39-953ef37c2eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 133ms/step - accuracy: 0.1070 - loss: 2.3023\n",
      "Epoch 2/2\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 136ms/step - accuracy: 0.1009 - loss: 2.3023\n",
      "CPU times: user 7min 1s, sys: 59.4 s, total: 8min 1s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    model.fit(x_train, y_train, epochs=2, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-m1-gpu",
   "language": "python",
   "name": "tensorflow-m1-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
